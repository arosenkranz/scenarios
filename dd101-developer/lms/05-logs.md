# Log Management

Large systems like the ones you work on produce thousands upon thousands of logs. They are stored in a multitude of places, with a variety of structures and content. Earlier in this course, you learned how Datadog integrations are instrumented to gather these logs and process them in Datadog with out-of-the-box pipelines, but that's only one half of the equation. The other half is understanding how to make sense of that log data to monitor the health of your application.

Log aggregation brings all your infrastructure, integration, and application logs together into one location, where you can slice and dice by tag and time frame, and group the logs by commonalities. It also allows you unify your log data with related trace metrics, allowing you to see a more complete story without switching contexts.

Datadog lets you see 100% of the most immediate logs, while also controlling which logs are retained for future reference. Your applications likely produce log data that is unique and important to your organization, so you can also create facets and measures out processed logs to help monitor key data points and detect trends over time.

In the next lab, you'll learn how to filter and visualize log data in the Datadog application. 
